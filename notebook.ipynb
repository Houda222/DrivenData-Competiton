{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://drivendata.co/blog/automated-abstraction-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import accelerate\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting dirs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"D:\\Donnees\\Desktop\\AI\\DrivenDataComp2\\data\") # replace with path to your data\n",
    "features = pd.read_csv(\n",
    "    DATA_DIR / \"train_features.csv\", index_col=\"uid\"\n",
    ")\n",
    "labels = pd.read_csv(\n",
    "    DATA_DIR / \"train_labels.csv\", index_col=\"uid\"\n",
    ")\n",
    "submission_format = pd.read_csv(\n",
    "    DATA_DIR / \"submission_format.csv\", index_col=\"uid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the comptetition's blogpost: In this notebook, we'll ignore NarrativeCME and use only NarrativeLE for simplicity. You may want to explore how better to consolidate information across these fields.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore feature data\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4000.000000\n",
       "mean      941.545750\n",
       "std       692.546272\n",
       "min       183.000000\n",
       "25%       497.000000\n",
       "50%       774.000000\n",
       "75%      1174.250000\n",
       "max      7487.000000\n",
       "Name: NarrativeLE, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.NarrativeLE.str.len().describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>50%</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DepressedMood</th>\n",
       "      <td>0.32800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentalIllnessTreatmentCurrnt</th>\n",
       "      <td>0.25850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistoryMentalIllnessTreatmnt</th>\n",
       "      <td>0.37250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuicideAttemptHistory</th>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuicideThoughtHistory</th>\n",
       "      <td>0.40950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubstanceAbuseProblem</th>\n",
       "      <td>0.22900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentalHealthProblem</th>\n",
       "      <td>0.48725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiagnosisAnxiety</th>\n",
       "      <td>0.13375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiagnosisDepressionDysthymia</th>\n",
       "      <td>0.36225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiagnosisBipolar</th>\n",
       "      <td>0.06550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiagnosisAdhd</th>\n",
       "      <td>0.05950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IntimatePartnerProblem</th>\n",
       "      <td>0.27975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilyRelationship</th>\n",
       "      <td>0.15425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argument</th>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SchoolProblem</th>\n",
       "      <td>0.10175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecentCriminalLegalProblem</th>\n",
       "      <td>0.07000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuicideNote</th>\n",
       "      <td>0.33850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuicideIntentDisclosed</th>\n",
       "      <td>0.27425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisclosedToIntimatePartner</th>\n",
       "      <td>0.08475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisclosedToOtherFamilyMember</th>\n",
       "      <td>0.09775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisclosedToFriend</th>\n",
       "      <td>0.06350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InjuryLocationType</th>\n",
       "      <td>1.97675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WeaponType1</th>\n",
       "      <td>5.65300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 mean  50%  min   max\n",
       "DepressedMood                 0.32800  0.0  0.0   1.0\n",
       "MentalIllnessTreatmentCurrnt  0.25850  0.0  0.0   1.0\n",
       "HistoryMentalIllnessTreatmnt  0.37250  0.0  0.0   1.0\n",
       "SuicideAttemptHistory         0.20950  0.0  0.0   1.0\n",
       "SuicideThoughtHistory         0.40950  0.0  0.0   1.0\n",
       "SubstanceAbuseProblem         0.22900  0.0  0.0   1.0\n",
       "MentalHealthProblem           0.48725  0.0  0.0   1.0\n",
       "DiagnosisAnxiety              0.13375  0.0  0.0   1.0\n",
       "DiagnosisDepressionDysthymia  0.36225  0.0  0.0   1.0\n",
       "DiagnosisBipolar              0.06550  0.0  0.0   1.0\n",
       "DiagnosisAdhd                 0.05950  0.0  0.0   1.0\n",
       "IntimatePartnerProblem        0.27975  0.0  0.0   1.0\n",
       "FamilyRelationship            0.15425  0.0  0.0   1.0\n",
       "Argument                      0.22100  0.0  0.0   1.0\n",
       "SchoolProblem                 0.10175  0.0  0.0   1.0\n",
       "RecentCriminalLegalProblem    0.07000  0.0  0.0   1.0\n",
       "SuicideNote                   0.33850  0.0  0.0   1.0\n",
       "SuicideIntentDisclosed        0.27425  0.0  0.0   1.0\n",
       "DisclosedToIntimatePartner    0.08475  0.0  0.0   1.0\n",
       "DisclosedToOtherFamilyMember  0.09775  0.0  0.0   1.0\n",
       "DisclosedToFriend             0.06350  0.0  0.0   1.0\n",
       "InjuryLocationType            1.97675  1.0  1.0   6.0\n",
       "WeaponType1                   5.65300  5.0  1.0  12.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore labels\n",
    "labels.describe().T[[\"mean\", \"50%\", \"min\", \"max\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the relatively lightweight Mistral-7B-Instruct-v0.2 model LLM for our solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path(\"assets\")\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(device, model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n",
    "    logger.info(f\"Using device {device} to save model to {MODEL_DIR}\")\n",
    "\n",
    "    # use 4-bit quantization\n",
    "    # quantization_config = BitsAndBytesConfig(\n",
    "    #     load_in_4bit=True,\n",
    "    #     bnb_4bit_compute_dtype=torch.float16,\n",
    "    # )\n",
    "\n",
    "    logger.info(\"Downloading model\")\n",
    "    # model = AutoModelForCausalLM.from_pretrained(\n",
    "    #     model_name, quantization_config=quantization_config, device_map=device\n",
    "    # )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, device_map=device\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    logger.info(f\"Saving model to {MODEL_DIR}\")\n",
    "    model.save_pretrained(MODEL_DIR)\n",
    "    tokenizer.save_pretrained(MODEL_DIR)\n",
    "    logger.success(\"Model and tokenizer saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Lenovo\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(\"token here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-20 13:50:42.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mDownloading model\u001b[0m\n",
      "\u001b[32m2024-09-20 13:50:42.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mUsing device cpu to save model to assets\u001b[0m\n",
      "\u001b[32m2024-09-20 13:50:42.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mDownloading model\u001b[0m\n",
      "Downloading shards: 100%|██████████| 3/3 [1:11:03<00:00, 1421.22s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.20s/it]\n",
      "\u001b[32m2024-09-20 15:02:53.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mSaving model to assets\u001b[0m\n",
      "\u001b[32m2024-09-20 15:11:42.632\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_model\u001b[0m:\u001b[36m22\u001b[0m - \u001b[32m\u001b[1mModel and tokenizer saved\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not (MODEL_DIR / \"config.json\").exists():\n",
    "    logger.info(\"Downloading model\")\n",
    "    save_model(DEVICE)\n",
    "else:\n",
    "    logger.info(\"Using existing local model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-20 15:13:18.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mLoading model from assets, True\u001b[0m\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:02<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loading model from {MODEL_DIR}, {MODEL_DIR.exists()}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR, device_map=DEVICE, local_files_only=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided a basic prompt here that defines:\n",
    "\n",
    "A role - an abstractor that takes narratives and returns values for the binary and categorical variables \n",
    "\n",
    "Lists of the variables we expect output for\n",
    "\n",
    "Options for the variable values\n",
    "\n",
    "Expected output format\n",
    "\n",
    "Example input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"You are an expert abstractor who reads law enforcement narratives about youth suicide and extracts variables that represent common patterns. The variables you are extracting are either binary (0 or 1) or categorical. Use the example input and output for the list of all variables to return.\n",
    "\n",
    "There are two categorical variables, specified below. For categorical variables, return ONE of the possible values specified in the semicolon-separated list.\n",
    "VARIABLE: InjuryLocationType\n",
    "- POSSIBLE VALUES: House, apartment; Motor vehicle (excluding school bus and public transportation); Natural area (e.g., field, river, beaches, woods); Street/road, sidewalk, alley; Park, playground, public use area; Other\n",
    "VARIABLE: WeaponType1\n",
    "- POSSIBLE VALUES: Firearm; Hanging, strangulation, suffocation; Poisoning; Fall; Other transport vehicle, eg, trains, planes, boats; Motor vehicle including buses, motorcycles; Drowning; Sharp instrument; Fire or burns; Blunt instrument; Unknown; Other (e.g. taser, electrocution, nail gun) \n",
    "\n",
    "All other variables are binary. For binary variables, Return a 0 if the item represented by the variable is absent and 1 if the item represented by the variable is present. The binary variables are:\n",
    "- DepressedMood\n",
    "- MentalIllnessTreatmentCurrnt\n",
    "- HistoryMentalIllnessTreatmnt\n",
    "- SuicideAttemptHistory\n",
    "- SuicideThoughtHistory\n",
    "- SubstanceAbuseProblem\n",
    "- MentalHealthProblem\n",
    "- DiagnosisAnxiety\n",
    "- DiagnosisDepressionDysthymia\n",
    "- DiagnosisBipolar\n",
    "- DiagnosisAdhd\n",
    "- IntimatePartnerProblem\n",
    "- FamilyRelationship\n",
    "- Argument\n",
    "- SchoolProblem\n",
    "- RecentCriminalLegalProblem\n",
    "- SuicideNote\n",
    "- SuicideIntentDisclosed\n",
    "- DisclosedToIntimatePartner\n",
    "- DisclosedToOtherFamilyMember\n",
    "- DisclosedToFriend\n",
    "\n",
    "You should output properly formatted json object where the keys are variable names and the values are predicted values for the given narrative. Do NOT output anything other than the JSON object. Do not include any explanation or summaries. Do not include any keys in this json object that aren't specified in the list.\n",
    "-------------\n",
    "EXAMPLE INPUT:\n",
    "XX XX V found deceased at home by his grandparents, hanging from a basketball hoop in his basement family room. According to LE, a check of V's cell phone revealed that V had made suicidal statements by phone earlier. In the text message V sent to his girlfriend, he had stated that he was going to hang himself.\n",
    "\n",
    "EXAMPLE OUTPUT:\n",
    "{{\"DepressedMood\": 0,\n",
    " \"MentalIllnessTreatmentCurrnt\": 0,\n",
    " \"HistoryMentalIllnessTreatmnt\": 0,\n",
    " \"SuicideAttemptHistory\": 0,\n",
    " \"SuicideThoughtHistory\": 0,\n",
    " \"SubstanceAbuseProblem\": 0,\n",
    " \"MentalHealthProblem\": 0,\n",
    " \"DiagnosisAnxiety\": 0,\n",
    " \"DiagnosisDepressionDysthymia\": 0,\n",
    " \"DiagnosisBipolar\": 0,\n",
    " \"DiagnosisAdhd\": 0,\n",
    " \"IntimatePartnerProblem\": 0,\n",
    " \"FamilyRelationship\": 0,\n",
    " \"Argument\": 0,\n",
    " \"SchoolProblem\": 0,\n",
    " \"RecentCriminalLegalProblem\": 0,\n",
    " \"SuicideNote\": 0,\n",
    " \"SuicideIntentDisclosed\": 1,\n",
    " \"DisclosedToIntimatePartner\": 1,\n",
    " \"DisclosedToOtherFamilyMember\": 0,\n",
    " \"DisclosedToFriend\": 0,\n",
    " \"InjuryLocationType\": \"House, apartment\",\n",
    " \"WeaponType1\": \"Hanging, strangulation, suffocation\"\n",
    "}}\n",
    "-------------\n",
    "INPUT:\n",
    "{}\n",
    "\n",
    "OUTPUT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll be batching our inputs in order to speed up prediction time (not all LLM pipelines will use batching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(features):\n",
    "    \"\"\"\n",
    "    Order features by ascending string length\n",
    "    \"\"\"\n",
    "    features[\"str_len\"] = features.NarrativeLE.str.len()\n",
    "    features = features.sort_values(by=\"str_len\")\n",
    "    return features.drop(columns=[\"str_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features(features, batch_size: int):\n",
    "    \"\"\"\n",
    "    Batch features together\n",
    "    \"\"\"\n",
    "    if len(features) > batch_size:\n",
    "        return np.array_split(features, int(len(features) / batch_size))\n",
    "    return [features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A padding token is used to fill shorter inputs in a batch to match the longest input's size, which ensures consistency in input size. Here, we're just using the end-of-sequence token as the padding token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "MAX_NEW_TOKENS=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_batch(feature_batch, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenize input batches, generate and decode outputs\n",
    "    \"\"\"\n",
    "    # Tokenize input narratives (NarrativeLE) in batch\n",
    "    prompts = [PROMPT_TEMPLATE.format(nar) for nar in feature_batch.NarrativeLE]\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True)\n",
    "    inputs.to(\"cuda\")\n",
    "\n",
    "    # Generate outputs for variables\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "    )\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    # Remove prompt from output\n",
    "    decoded = [resp[len(prompt) :] for resp, prompt in zip(decoded, prompts)]\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch inputs - note - we're running an example of 5 in this notebook\n",
    "df = process_features(features.iloc[:5])\n",
    "data_batches = batch_features(df, BATCH_SIZE)\n",
    "\n",
    "responses = []\n",
    "idxs = []\n",
    "logger.info(f\"Iterating over {len(data_batches)} batches\")\n",
    "for ix, data_batch in enumerate(data_batches):\n",
    "    logger.info(f\"Generating predictions on batch {ix}, with {len(data_batch)} samples\")\n",
    "    responses += predict_on_batch(data_batch, model, tokenizer)\n",
    "    idxs += list(data_batch.index)\n",
    "logger.info(f\"Finished inference\")\n",
    "interim_preds = pd.DataFrame({\"string_output\": responses}, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(responses[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse model outputs into submission-ready format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(output):\n",
    "    \"\"\"\n",
    "    Transform response into a json object using minimal cleaning\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try loading the raw string into \n",
    "        resp = json.loads(output)\n",
    "        return resp\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    try:\n",
    "        # Get rid of extra trailing sections that follow \"--\"\n",
    "        split_output = output.split(\"--\")[0]\n",
    "        resp = json.loads(split_output)\n",
    "        return resp\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    try:\n",
    "        # Get rid of sections that follow the a closing bracket \"}\"\n",
    "        split_output = output.split(\"}\")[0] + \"}\"\n",
    "        resp = json.loads(split_output)\n",
    "        return resp\n",
    "    except json.JSONDecodeError:\n",
    "        logger.warning(f\"Failed to parse {output} into valid json\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_injury_location(data: pd.Series):\n",
    "    \"\"\"\n",
    "    Transform InjuryLocationType model output to integers, \n",
    "    fill in default for invalid outputs\n",
    "    \"\"\"\n",
    "    ilt = data.map(\n",
    "        {\n",
    "            \"House, apartment\": 1,\n",
    "            \"Motor vehicle (excluding school bus and public transportation)\": 2,\n",
    "            \"Natural area (e.g., field, river, beaches, woods)\": 3,\n",
    "            \"Park, playground, public use area\": 4,\n",
    "            \"Street/road, sidewalk, alley\": 5,\n",
    "            \"Other\": 6,\n",
    "            \"Residence\": 1,\n",
    "            \"Apartment\": 1,\n",
    "        }\n",
    "    )\n",
    "    if ilt.isna().any():\n",
    "        logger.warning(\n",
    "            f\"There are unexpected values in injury location: {data[ilt.isna()].unique()} \"\n",
    "        )\n",
    "        ilt = ilt.fillna(6)  # Fill with other\n",
    "\n",
    "    return ilt.astype(int)\n",
    "\n",
    "\n",
    "def process_weapon_type(data: pd.Series):\n",
    "    \"\"\"\n",
    "    Transform WeaponType1 model output to integers, \n",
    "    fill in default for invalid outputs\n",
    "    \"\"\"\n",
    "    wt = data.map(\n",
    "        {\n",
    "            \"Blunt instrument\": 1,\n",
    "            \"Drowning\": 2,\n",
    "            \"Fall\": 3,\n",
    "            \"Fire or burns\": 4,\n",
    "            \"Firearm\": 5,\n",
    "            \"Hanging, strangulation, suffocation\": 6,\n",
    "            \"Motor vehicle including buses, motorcycles\": 7,\n",
    "            \"Other transport vehicle, eg, trains, planes, boats\": 8,\n",
    "            \"Poisoning\": 9,\n",
    "            \"Sharp instrument\": 10,\n",
    "            \"Other (e.g. taser, electrocution, nail gun)\": 11,\n",
    "            \"Unknown\": 12,\n",
    "        }\n",
    "    )\n",
    "    if wt.isna().any():\n",
    "        logger.warning(\n",
    "            f\"There are unexpected values in weapon type: {data[wt.isna()].unique()} \"\n",
    "        )\n",
    "        wt = wt.fillna(11)  # Fill with other\n",
    "\n",
    "    return wt.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "parsed_resps = []\n",
    "could_not_parse = []\n",
    "\n",
    "for row in interim_preds.itertuples():\n",
    "    parsed = parse_response(row.string_output)\n",
    "    if type(parsed) == dict:\n",
    "        idxs.append(row.Index)\n",
    "        parsed_resps.append(parsed)\n",
    "    else:\n",
    "        idxs.append(row.Index)\n",
    "        could_not_parse.append(row.Index)\n",
    "        # Fill any we couldn't parse with placeholder values for now\n",
    "        parsed_resps.append(\n",
    "            {\n",
    "                \"DepressedMood\": 0,\n",
    "                \"IntimatePartnerProblem\": 0,\n",
    "                \"FamilyRelationship\": 0,\n",
    "                \"Argument\": 0,\n",
    "                \"MentalIllnessTreatmentCurrnt\": 0,\n",
    "                \"HistoryMentalIllnessTreatmnt\": 0,\n",
    "                \"SuicideAttemptHistory\": 0,\n",
    "                \"SuicideThoughtHistory\": 0,\n",
    "                \"SuicideNote\": 0,\n",
    "                \"SubstanceAbuseProblem\": 0,\n",
    "                \"SchoolProblem\": 0,\n",
    "                \"RecentCriminalLegalProblem\": 0,\n",
    "                \"SuicideIntentDisclosed\": 0,\n",
    "                \"DisclosedToIntimatePartner\": 0,\n",
    "                \"DisclosedToOtherFamilyMember\": 0,\n",
    "                \"DisclosedToFriend\": 0,\n",
    "                \"MentalHealthProblem\": 0,\n",
    "                \"DiagnosisAnxiety\": 0,\n",
    "                \"DiagnosisDepressionDysthymia\": 0,\n",
    "                \"DiagnosisBipolar\": 0,\n",
    "                \"DiagnosisAdhd\": 0,\n",
    "                \"WeaponType1\": \"Unknown\",\n",
    "                \"InjuryLocationType\": \"Other\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "if len(could_not_parse) > 0:\n",
    "    logger.warning(\n",
    "        f\"Could not parse {len(could_not_parse)} rows. Indices: {could_not_parse}\"\n",
    "    )\n",
    "\n",
    "parsed_preds = pd.DataFrame(parsed_resps, index=pd.Index(idxs, name=\"uid\")).fillna(0)\n",
    "parsed_preds[\"InjuryLocationType\"] = process_injury_location(\n",
    "    parsed_preds.InjuryLocationType\n",
    ")\n",
    "parsed_preds[\"WeaponType1\"] = process_weapon_type(parsed_preds.WeaponType1)\n",
    "\n",
    "# Make sure the column order is the same as in the submission format\n",
    "parsed_preds = parsed_preds[submission_format.columns]\n",
    "\n",
    "# Make sure the row order is the same as in the submission format\n",
    "parsed_preds = parsed_preds.loc[features[:5].index]\n",
    "\n",
    "# Make sure all values are int\n",
    "parsed_preds = parsed_preds.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns are in the correct order\n",
    "assert (submission_format.columns == parsed_preds.columns).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns are of type int\n",
    "assert (parsed_preds.dtypes == int).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables have values within the expected range\n",
    "assert parsed_preds.iloc[:, 0:-2].isin([0, 1]).all().all()\n",
    "assert (parsed_preds[\"InjuryLocationType\"].isin(range(1, 7))).all()\n",
    "assert (parsed_preds[\"WeaponType1\"].isin(range(1, 13))).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
